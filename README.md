# ðŸ–¼ï¸ Image Captioning with ResNet-50 + LSTM (Flickr8k)

This project implements an image captioning system using an **Encoderâ€“Decoder architecture**, where a **pretrained ResNet-50** model extracts visual features and a **stacked LSTM** generates natural language descriptions. Trained on the **Flickr8k dataset**, the model achieves **BLEU-1 of 65%** and **BLEU-2 of 42%**, outperforming the original benchmark. ðŸš€

---

## âœ¨ Key Features
- ðŸ§  Encoderâ€“Decoder pipeline (ResNet-50 + LSTM)
- ðŸ“Š BLEU-1 to BLEU-4 score evaluation
- ðŸ”¤ Caption tokenization, padding, and sequence generation
- ðŸ“ Complete preprocessing + feature extraction workflow
- ðŸ“ˆ Training visualization and performance tracking

---

## ðŸ“ Dataset
**Flickr8k Dataset**
- 8,000 images  
- 5 captions per image  
- Publicly available dataset and caption files  

---

## ðŸ› ï¸ Technologies Used
- Python  
- TensorFlow / Keras  
- ResNet-50 (ImageNet pretrained)  
- LSTM  
- NumPy, Matplotlib, Pickle, tqdm  

---

## ðŸ§© Model Architecture

### ðŸ”· Encoder
- Pretrained **ResNet-50**, classification head removed  
- Produces **2048-dimensional** feature vectors  

### ðŸ”¶ Decoder
- Embedding layer  
- Stacked LSTM layers  
- Dense layer for next-word prediction  

---

## ðŸ“Š Results

| Metric | Score |
|--------|--------|
| â­ BLEU-1 | 65% |
| â­ BLEU-2 | 42% |
| â­ BLEU-3 | 27% |
| â­ BLEU-4 | 18% |

> ðŸ“ˆ The model surpasses the reference implementation (BLEU-1: 61%, BLEU-2: 41%).

---
